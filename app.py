# --- Gerekli TÃ¼m KÃ¼tÃ¼phaneler ---
import time
import json
import threading
import queue
import pandas as pd
import numpy as np
import joblib
import statistics
from collections import defaultdict
from flask import Flask, render_template, Response
from scapy.all import sniff, IP, TCP, UDP

# --- FLASK UYGULAMASI ---
app = Flask(__name__)

ANOMALY_THRESHOLD = 0.85 #87

# --- MODEL YÃœKLEME ---
try:
    model_pipeline = joblib.load('models/unsw_rf_model_v4.pkl')
    print("âœ… Model 'unsw_rf_model_v4.pkl' baÅŸarÄ±yla yÃ¼klendi.")
    FINAL_MODEL_COLUMNS = model_pipeline.feature_names_in_
    print(f"ğŸ”¬ Modelin beklediÄŸi {len(FINAL_MODEL_COLUMNS)} sÃ¼tun adÄ± baÅŸarÄ±yla alÄ±ndÄ±.")
except Exception as e:
    print(f"âŒ HATA: Model yÃ¼klenirken bir sorun oluÅŸtu: {e}")
    model_pipeline = None
    FINAL_MODEL_COLUMNS = []

# --- VERÄ° KUYRUÄU VE FLOW MANAGER MANTIÄI ---
data_queue = queue.Queue()
AKIS_ZAMAN_ASIMI = 30 # Test iÃ§in zaman aÅŸÄ±mÄ±nÄ± 15 saniyeye dÃ¼ÅŸÃ¼rdÃ¼k!
active_flows = {}
lock = threading.Lock()

def get_flow_key(paket):
    if IP in paket:
        p = paket[IP]
        proto_num = p.proto
        if TCP in paket or UDP in paket:
            sport, dport = p.sport, p.dport
            if p.src < p.dst:
                return (p.src, sport, p.dst, dport, proto_num)
            else:
                return (p.dst, dport, p.src, sport, proto_num)
    return None

def finalize_flow_and_queue(flow_key, flow_data):
    """ Bir akÄ±ÅŸ bittiÄŸinde Ã¶zelliklerini hesaplar ve bir dictionary olarak kuyruÄŸa atar. """
    print(f"\n[6] AkÄ±ÅŸ sonlandÄ±rma fonksiyonu Ã§aÄŸrÄ±ldÄ±: {flow_key}")
    try:
        dur = flow_data['last_seen'] - flow_data['start_time']
        if dur <= 0: dur = 0.000001
        total_pkts = flow_data['spkts'] + flow_data['dpkts']
        proto_map = {1: 'icmp', 6: 'tcp', 17: 'udp'}
        proto_str = proto_map.get(flow_key[4], 'other')
        flow_dict = {
            'dur': dur, 'proto': proto_str, 'service': flow_data.get('service', '-'),
            'state': flow_data.get('state', 'INT'), 'spkts': flow_data['spkts'],
            'dpkts': flow_data['dpkts'], 'sbytes': flow_data['sbytes'], 'dbytes': flow_data['dbytes'],
            'rate': total_pkts / dur if dur > 0 else 0, 'sttl': flow_data['sttl'],
            'dttl': flow_data.get('dttl', 0), 'sload': (flow_data['sbytes'] * 8) / dur if dur > 0 else 0,
            'dload': (flow_data['dbytes'] * 8) / dur if dur > 0 else 0, 'sloss': 0, 'dloss': 0,
            'sinpkt': statistics.mean(flow_data['sinpkt_list']) if len(flow_data['sinpkt_list']) > 0 else 0,
            'dinpkt': statistics.mean(flow_data['dinpkt_list']) if len(flow_data['dinpkt_list']) > 0 else 0,
            'sjit': statistics.pstdev(flow_data['sinpkt_list']) if len(flow_data['sinpkt_list']) > 1 else 0,
            'djit': statistics.pstdev(flow_data['dinpkt_list']) if len(flow_data['dinpkt_list']) > 1 else 0,
            'swin': flow_data.get('swin', 0), 'stcpb': flow_data.get('stcpb', 0),
            'dtcpb': flow_data.get('dtcpb', 0), 'dwin': flow_data.get('dwin', 0),
            'tcprtt': 0, 'synack': 0, 'ackdat': 0,
            'smean': int(flow_data['sbytes'] / flow_data['spkts']) if flow_data['spkts'] > 0 else 0,
            'dmean': int(flow_data['dbytes'] / flow_data['dpkts']) if flow_data['dpkts'] > 0 else 0,
            'trans_depth': 0, 'response_body_len': 0, 'ct_srv_src': 1, 'ct_state_ttl': 0,
            'ct_dst_ltm': 1, 'ct_src_dport_ltm': 1, 'ct_dst_sport_ltm': 1, 'ct_dst_src_ltm': 1,
            'is_ftp_login': 0, 'ct_ftp_cmd': 0, 'ct_flw_http_mthd': 0, 'ct_src_ltm': 1,
            'ct_srv_dst': 1, 'is_sm_ips_ports': 0
        }
        data_queue.put(flow_dict)
        print(f"\n[+] AkÄ±ÅŸ BaÅŸarÄ±yla KuyruÄŸa Eklendi!")
    except Exception as e:
        print(f"\nâŒ HATA (finalize_flow_and_queue): {e}")

def process_packet(paket):
    """ Her paketi iÅŸleyen ana fonksiyon. (Kontrol NoktalarÄ± Eklendi) """
    # print(".", end="", flush=True) # [1] Paket yakalandÄ± mÄ±?
    flow_key = get_flow_key(paket)
    if not flow_key:
        return
    # print(":", end="", flush=True) # [2] GeÃ§erli bir akÄ±ÅŸ anahtarÄ± var mÄ±?

    now = time.time()
    src_ip_key_in_flow = flow_key[0]
    
    with lock:
        if flow_key not in active_flows:
            # print("N", end="", flush=True) # [3] Yeni bir akÄ±ÅŸ mÄ±?
            active_flows[flow_key] = defaultdict(lambda: 0, {
                'start_time': now, 'last_seen': now, 'spkts': 0, 'dpkts': 0, 
                'sbytes': 0, 'dbytes': 0, 'sttl': 0, 'sinpkt_list': [], 
                'dinpkt_list': [], 'last_spkt_time': 0, 'last_dpkt_time': 0
            })
        # else:
        #     print("U", end="", flush=True) # [4] Mevcut bir akÄ±ÅŸ mÄ± gÃ¼ncelleniyor?
        
        flow_data = active_flows[flow_key]
        flow_data['last_seen'] = now
        p = paket[IP]
        is_packet_from_flow_src_to_flow_dst = (p.src == src_ip_key_in_flow)
        
        if is_packet_from_flow_src_to_flow_dst:
            flow_data['spkts'] += 1; flow_data['sbytes'] += len(p)
            if flow_data['sttl'] == 0: flow_data['sttl'] = p.ttl
            if flow_data['last_spkt_time'] != 0: flow_data['sinpkt_list'].append(now - flow_data['last_spkt_time'])
            flow_data['last_spkt_time'] = now
            if TCP in p:
                if 'swin' not in flow_data: flow_data['swin'] = p[TCP].window
                if 'stcpb' not in flow_data: flow_data['stcpb'] = p[TCP].seq
        else:
            flow_data['dpkts'] += 1; flow_data['dbytes'] += len(p)
            if 'dttl' not in flow_data: flow_data['dttl'] = p.ttl
            if flow_data['last_dpkt_time'] != 0: flow_data['dinpkt_list'].append(now - flow_data['last_dpkt_time'])
            flow_data['last_dpkt_time'] = now
            if TCP in p:
                if 'dwin' not in flow_data: flow_data['dwin'] = p[TCP].window
                if 'dtcpb' not in flow_data: flow_data['dtcpb'] = p[TCP].seq
        
        if TCP in p and (p[TCP].flags.F or p[TCP].flags.R):
            print("F", end="", flush=True) # [5] FIN/RST paketiyle akÄ±ÅŸ sonlanÄ±yor mu?
            flow_data['state'] = 'FIN' if p[TCP].flags.F else 'RST'
            finalize_flow_and_queue(flow_key, active_flows.pop(flow_key))

def timeout_checker():
    """ Zaman aÅŸÄ±mÄ±na uÄŸrayan akÄ±ÅŸlarÄ± periyodik olarak kontrol eder. """
    while True:
        time.sleep(AKIS_ZAMAN_ASIMI)
        print(f"\n[7] Zaman aÅŸÄ±mÄ± kontrolÃ¼ Ã§alÄ±ÅŸÄ±yor (aktif akÄ±ÅŸ sayÄ±sÄ±: {len(active_flows)})...")
        now = time.time()
        with lock:
            timed_out_keys = [key for key, data in active_flows.items() if now - data['last_seen'] > AKIS_ZAMAN_ASIMI]
            if timed_out_keys:
                print(f"\n[8] {len(timed_out_keys)} adet zaman aÅŸÄ±mÄ±na uÄŸrayan akÄ±ÅŸ bulundu!")
            for key in timed_out_keys:
                active_flows[key]['state'] = 'INT' 
                finalize_flow_and_queue(key, active_flows.pop(key))

def start_packet_capture():
    """ Paket yakalamayÄ± baÅŸlatan ana fonksiyon. """
    print("ğŸš€ Arka Plan: Paket yakalama motoru baÅŸlatÄ±lÄ±yor...")
    ARAYUZ_ADI = "Wi-Fi" 
    print(f" dinlenecek aÄŸ arayÃ¼zÃ¼: {ARAYUZ_ADI}")
    try:
        # Lambda testini kaldÄ±rÄ±p orijinal process_packet'e geri dÃ¶nÃ¼yoruz.
        sniff(iface=ARAYUZ_ADI, prn=process_packet, store=False, filter="ip")
    except Exception as e:
        print(f"\nâŒ HATA (start_packet_capture): {e}")

# app.py iÃ§inde, mevcut get_anomaly_explanation fonksiyonunu bununla deÄŸiÅŸtirin.

def get_anomaly_explanation(flow_data):
    """
    Anomali olarak iÅŸaretlenen bir akÄ±ÅŸ iÃ§in insan tarafÄ±ndan okunabilir,
    kural tabanlÄ± olasÄ± nedenler Ã¼retir. (KALÄ°BRE EDÄ°LMÄ°Å HALÄ°)
    """
    reasons = []
    
    # Kural 1: Paket oranÄ± (rate) - EÅŸiÄŸi dÃ¼ÅŸÃ¼rdÃ¼k
    if flow_data.get('rate', 0) > 100: # EÅŸik 1000'den 100'e dÃ¼ÅŸÃ¼rÃ¼ldÃ¼
        reasons.append(f"YÃ¼ksek paket oranÄ± ({flow_data['rate']:.0f} pps)")

    # Kural 2: Kaynak yÃ¼kÃ¼ (sload) - EÅŸiÄŸi dramatik ÅŸekilde dÃ¼ÅŸÃ¼rdÃ¼k
    if flow_data.get('sload', 0) > 500000: # EÅŸik 20 Milyon'dan 500 Bin'e dÃ¼ÅŸÃ¼rÃ¼ldÃ¼ (0.5 Mbps)
        reasons.append(f"YÃ¼ksek kaynak veri yÃ¼kÃ¼ ({flow_data['sload']/1000000:.2f} Mbps)")

    # Kural 3: KÄ±sa sÃ¼rede veri gÃ¶nderimi - EÅŸiÄŸi dÃ¼ÅŸÃ¼rdÃ¼k
    if flow_data.get('dur', 1) < 2 and flow_data.get('sbytes', 0) > 4000: # EÅŸik 50KB'den 4KB'ye dÃ¼ÅŸÃ¼rÃ¼ldÃ¼
        reasons.append("KÄ±sa sÃ¼rede yÃ¼ksek hacimli veri gÃ¶nderimi")
        
    # Kural 4: Paketler arasÄ± Ã§ok dÃ¼ÅŸÃ¼k varÄ±ÅŸ zamanÄ±
    # Bu kural LAN Ã¼zerinde Ã§ok hassas olabilir, ÅŸimdilik eÅŸiÄŸi koruyalÄ±m.
    if flow_data.get('sinpkt', 0) > 0 and flow_data.get('sinpkt', 100) < 0.01:
        reasons.append("Paketler arasÄ± Ã§ok dÃ¼ÅŸÃ¼k varÄ±ÅŸ zamanÄ±")

    # Kural 5: AkÄ±ÅŸ Ã§ok uzun sÃ¼rÃ¼yorsa (Bu kural aynÄ± kalabilir)
    if flow_data.get('dur', 0) > 300:
        reasons.append("Ã‡ok uzun sÃ¼ren baÄŸlantÄ± akÄ±ÅŸÄ±")

    if not reasons:
        return "Model, Ã¶zelliklerin genel bir kombinasyonuna dayanarak anomali tespit etti."
        
    return "OlasÄ± Neden(ler): " + ", ".join(reasons) + "."
# --- FLASK ROTALARI ---
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/stream')
def stream():
    """ GerÃ§ek zamanlÄ± veri akÄ±ÅŸÄ±nÄ± SSE Ã¼zerinden sunar. (DÃœZELTÄ°LMÄ°Å HALÄ°) """
    if model_pipeline is None:
        def error_stream():
            error_data = {"error": "Model yÃ¼klenemedi. Sunucu loglarÄ±nÄ± kontrol edin."}
            yield f"data: {json.dumps(error_data)}\n\n"
        return Response(error_stream(), mimetype='text/event-stream')

    def realtime_event_stream():
        print("ğŸ”— Ä°stemci baÄŸlandÄ±. Veri akÄ±ÅŸÄ± baÅŸlÄ±yor...")
        while True:
            try:
                # 1. Kuyruktan ham veriyi al ('proto': 'tcp' gibi metinlerle birlikte)
                flow_data_dict = data_queue.get()
                
                # 2. SADECE DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r. Manuel Ã¶n iÅŸleme (get_dummies, reindex) YOK!
                live_df = pd.DataFrame([flow_data_dict])
                
                # 3. Ham DataFrame'i doÄŸrudan 'akÄ±llÄ±' pipeline'a gÃ¶nder.
                # Pipeline, Ã¶lÃ§eklendirme ve one-hot-encoding gibi tÃ¼m adÄ±mlarÄ± kendisi yapacak.
                probability_scores = model_pipeline.predict_proba(live_df)[0]
                
                # --- Buradan sonrasÄ± aynÄ± ---
                normal_probability = probability_scores[0]
                anomaly_probability = probability_scores[1]
                
                prediction = 1 if anomaly_probability >= ANOMALY_THRESHOLD else 0
                
                explanation = ""
                if prediction == 1:
                    explanation = get_anomaly_explanation(flow_data_dict)

                result = {
                    'data': flow_data_dict,
                    'prediction': int(prediction),
                    'probability_anomaly': round(float(anomaly_probability), 3),
                    'probability_normal': round(float(normal_probability), 3),
                    'explanation': explanation
                }

                 # --- BU DEBUG SATIRINI GERÄ° EKLEYÄ°N ---
                # Sadece anomali olabilecekleri gÃ¶rmek iÃ§in bir if koÅŸulu ekleyelim
                if anomaly_probability > 0.1: # Sadece %10'dan ÅŸÃ¼pheli olanlarÄ± yazdÄ±r
                    print(f">>> MODEL TAHMÄ°NÄ°: Anomali OlasÄ±lÄ±ÄŸÄ± = {anomaly_probability:.3f}")
                # --- DEBUG KODU SONU ---
                
                yield f"data: {json.dumps(result)}\n\n"
                 # EÄŸer kuyrukta hala Ã§ok fazla veri bekliyorsa (Ã¶rn: 50'den fazla),
                # arayÃ¼zÃ¼n yetiÅŸebilmesi iÃ§in Ã§ok kÄ±sa bir sÃ¼re (Ã¶rn: 50 milisaniye) bekle.
                # if data_queue.qsize() > 50:
                #     time.sleep(0.05) 

            except Exception as e:
                print(f"âŒ HATA (stream fonksiyonu): {e}")
                if 'live_df' in locals():
                    print(f"ğŸš¨ Modele gÃ¶nderilmeye Ã§alÄ±ÅŸÄ±lan son veri: {live_df.to_dict()}")

    return Response(realtime_event_stream(), mimetype='text/event-stream')
    """ GerÃ§ek zamanlÄ± veri akÄ±ÅŸÄ±nÄ± SSE Ã¼zerinden sunar. """
    if model_pipeline is None:
        def error_stream():
            error_data = {"error": "Model yÃ¼klenemedi. Sunucu loglarÄ±nÄ± kontrol edin."}
            yield f"data: {json.dumps(error_data)}\n\n"
        return Response(error_stream(), mimetype='text/event-stream')

    def realtime_event_stream():
        print("ğŸ”— Ä°stemci baÄŸlandÄ±. GerÃ§ek zamanlÄ± veri akÄ±ÅŸÄ± baÅŸlÄ±yor...")
        while True:
            try:
                flow_data_dict = data_queue.get()
                live_df = pd.DataFrame([flow_data_dict])
                probability_scores = model_pipeline.predict_proba(live_df)[0]
                
                # live_df = pd.DataFrame([flow_data_dict])
                # live_df_encoded = pd.get_dummies(live_df)
                # live_df_aligned = live_df_encoded.reindex(columns=FINAL_MODEL_COLUMNS, fill_value=0)
                
                probability_scores = model_pipeline.predict_proba(live_df_aligned)[0]
                anomaly_probability = probability_scores[1]
                
                print(f"--- DEBUG: KarÅŸÄ±laÅŸtÄ±rma -> OlasÄ±lÄ±k: {anomaly_probability:.2f} >= EÅŸik: {ANOMALY_THRESHOLD} ? ---")
                
                prediction = 1 if anomaly_probability >= ANOMALY_THRESHOLD else 0
                
                explanation = ""
                if prediction == 1:
                    explanation = get_anomaly_explanation(flow_data_dict)

                result = {
                    'data': flow_data_dict,
                    'prediction': int(prediction),
                    'probability_anomaly': round(float(anomaly_probability), 3),
                    'probability_normal': round(float(normal_probability), 3),
                    'explanation': explanation
                }
                # --- EN KRÄ°TÄ°K DEBUG KODU BAÅLANGICI ---
                print("\n" + "-"*50)
                print(">>> SUNUCU TARAFINDAN GÃ–NDERÄ°LMEDEN Ã–NCEKÄ° VERÄ° (app.py) <<<")
                print("RESULT SÃ–ZLÃœÄÃœ:", result)
                # OlasÄ±lÄ±k deÄŸerinin Python'daki tipini kontrol edelim
                if 'probability_anomaly' in result:
                    print("probability_anomaly'nin TÄ°PÄ°:", type(result['probability_anomaly']))
                else:
                    print("DÄ°KKAT: 'probability_anomaly' anahtarÄ± result iÃ§inde bulunamadÄ±!")
                print("-"*50)
                # --- DEBUG KODU SONU ---




                yield f"data: {json.dumps(result)}\n\n"

            except Exception as e:
                print(f"âŒ HATA (stream fonksiyonu): {e}")
                if 'live_df_aligned' in locals():
                    print(f"ğŸš¨ Modele gÃ¶nderilmeye Ã§alÄ±ÅŸÄ±lan son hizalanmÄ±ÅŸ veri: {live_df_aligned.to_dict()}")

    return Response(realtime_event_stream(), mimetype='text/event-stream')

# --- ANA PROGRAM BAÅLANGICI ---
if __name__ == '__main__':
    capture_thread = threading.Thread(target=start_packet_capture, daemon=True)
    timeout_thread = threading.Thread(target=timeout_checker, daemon=True)
    
    capture_thread.start()
    timeout_thread.start()

    app.run(debug=False, host='0.0.0.0', port=5000, threaded=True, use_reloader=False)